"""
ê°„ë‹¨í•œ LLM ì—°ê²° ì˜ˆì œ

Ollamaì™€ LangChainì„ ì—°ê²°í•´ì„œ ì‹¤ì œë¡œ LLM ì‘ë‹µì„ ë°›ì•„ë´…ë‹ˆë‹¤.

ğŸ¯ ëª©í‘œ:
- Ollama.app GUI vs LangChain ë™ì‘ ì°¨ì´ ì´í•´
- ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ì‘ë‹µì— ë¯¸ì¹˜ëŠ” ì˜í–¥ í™•ì¸

ì‹¤í–‰:
    uv run python -m src.examples.06_simple_llm
"""

from langchain_ollama import ChatOllama


def main():
    print("=" * 80)
    print("  ğŸ¤– LLM ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¹„êµ í…ŒìŠ¤íŠ¸")
    print("=" * 80)

    # Ollama LLM ì´ˆê¸°í™” (verbose=Trueë¡œ LangChain ë¡œê¹… í™œì„±í™”)
    llm = ChatOllama(
        model="gpt-oss:20b",
        temperature=0.0,  # ì¼ê´€ëœ ì‘ë‹µì„ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •
        verbose=True,  # â­ LangChainì´ ìë™ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸/ì‘ë‹µ ë¡œê¹…
    )

    user_query = "ë‚´ì¼ ì˜¤í›„ 2ì‹œì— íŒ€ íšŒì˜ ì¼ì • ì¡ì•„ì¤˜"

    # ========================================================================
    # Case 1: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì—†ìŒ (LangChain ê¸°ë³¸)
    # ========================================================================
    print("\n" + "=" * 80)
    print("1ï¸âƒ£  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì—†ìŒ (LangChain ê¸°ë³¸)")
    print("=" * 80)
    print(f"\nì§ˆì˜: {user_query}")

    response = llm.invoke(user_query)
    print(f"\nì‘ë‹µ ê¸¸ì´: {len(response.content)} ê¸€ì")
    print(f"ì‘ë‹µ ì‹œì‘ 100ì:\n{response.content}")

    # ========================================================================
    # Case 2: ê±°ë¶€í•˜ë„ë¡ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    # ========================================================================
    print("\n" + "=" * 80)
    print("2ï¸âƒ£  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: ìº˜ë¦°ë” ì ‘ê·¼ ë¶ˆê°€ (ê°•ì œ ê±°ë¶€)")
    print("=" * 80)

    messages = [
        (
            "system",
            "You cannot schedule events. You have no access to calendars. Always refuse politely.",
        ),
        ("human", user_query),
    ]

    response = llm.invoke(messages)
    print(f"\nì§ˆì˜: {user_query}")
    print(f"\nì‘ë‹µ:\n{response.content}")

    # ========================================================================
    # Case 3: Ollama.appê³¼ ë™ì¼í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    # ========================================================================
    print("\n" + "=" * 80)
    print("3ï¸âƒ£  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: Ollama.app GUIì™€ ë™ì¼ (ChatGPT ì—­í• )")
    print("=" * 80)

    messages = [
        (
            "system",
            """You are ChatGPT, a large language model trained by OpenAI.
Knowledge cutoff: 2024-06
Current date: 2025-11-12

Reasoning: medium

When asked to perform actions (like scheduling), think about whether you actually have the capability to do so.""",
        ),
        ("human", user_query),
    ]

    response = llm.invoke(messages)
    print(f"\nì§ˆì˜: {user_query}")
    print(f"\nì‘ë‹µ:\n{response.content}")

    # ========================================================================
    # ê²°ë¡ 
    # ========================================================================
    print("\n" + "=" * 80)
    print("  ğŸ’¡ í•µì‹¬ ë°œê²¬")
    print("=" * 80)
    print(
        """
1ï¸âƒ£  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì—†ìŒ:
   â†’ LLMì´ ë‹¨ìˆœíˆ "ë„ì™€ì£¼ëŠ”" í…ìŠ¤íŠ¸ ìƒì„±
   â†’ ì‹¤ì œ ìº˜ë¦°ë” ì ‘ê·¼ ì—†ì´ë„ ì¹œì ˆí•˜ê²Œ ì‘ë‹µ

2ï¸âƒ£  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¡œ ì œì•½ ì¶”ê°€:
   â†’ "ìº˜ë¦°ë” ì ‘ê·¼ ë¶ˆê°€"ë¼ê³  ëª…ì‹œí•˜ë©´ ê±°ë¶€
   â†’ Ollama.app GUIê°€ ì´ëŸ° ë°©ì‹ìœ¼ë¡œ ë™ì‘

3ï¸âƒ£  Ollama.appê³¼ ë™ì¼í•œ í”„ë¡¬í”„íŠ¸:
   â†’ "ChatGPTì²˜ëŸ¼ í–‰ë™" + "Reasoning: medium"
   â†’ ëª¨ë¸ì´ ìê¸° ëŠ¥ë ¥ì„ íŒë‹¨í•˜ê³  ê±°ë¶€

ğŸ¯ ê²°ë¡ :
   - Ollama.app GUI â‰  LangChain (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì°¨ì´)
   - ìš°ë¦¬ ì‹œìŠ¤í…œì€ LangChain ì‚¬ìš© = ë¬¸ì œì—†ìŒ!
   - parse_event_infoëŠ” ëª…í™•í•œ ì§€ì‹œë¡œ ì •ë³´ë§Œ ì¶”ì¶œ = ì‘ë™ ì™„ë²½!
    """
    )

    print("=" * 80)
    print("  âœ¨ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 80)


if __name__ == "__main__":
    main()
